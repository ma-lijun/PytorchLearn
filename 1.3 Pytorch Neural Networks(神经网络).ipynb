{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba85c5e3-ba48-4a77-ba93-d9d9823b5c3e",
   "metadata": {},
   "source": [
    "1.3 Pytorch Neural Networks(神经网络)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dcb43a-1bb2-4371-ad75-7c79de1a97d6",
   "metadata": {},
   "source": [
    "### 1. 使用torch.nn包来构建神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62af99b-1ddc-42d6-b135-1702e33d5e4e",
   "metadata": {},
   "source": [
    "> 由上一讲了解了autograd, nn包依赖 autograd 包来定义模型并求导。一个nn.Module包含各个层和一个forward(input)方法，该方法返回output。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b075f989-2eb1-44e5-b2c5-8d38da8b5857",
   "metadata": {},
   "source": [
    "![Alexnet网络示例](./img/alexnet20220517154203.png \"网络模型\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f5b39b-97c1-4641-ab2f-d76a1e0802f9",
   "metadata": {},
   "source": [
    "> 这是一个简单的前馈神经网络， 它接受一个输入， 然后一层接着一层地传递， 最后输出计算结果。\n",
    "\n",
    "> 神经网络的典型训练过程如下：\n",
    "\n",
    "    1. 定义包含一些可学习参数（或者叫权重）的神经网络模型；\n",
    "    2. 在数据集上迭代；\n",
    "    3. 通过神经网络处理输入；\n",
    "    4. 计算损失（输出结果和正确值的差值大小）；\n",
    "    5. 将梯度反向传播回网格的参数；\n",
    "    6. 更新网格的参数， 主要使用如下简单的更新原则： weight = weight - learning_rate*gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe43331-4e42-4b19-9426-cb1082ffc60b",
   "metadata": {},
   "source": [
    "### 2. 定义网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ff49e69-bb45-4e0d-b930-1009d47857a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "718dba39-b50c-4137-9d53-19cfa453b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5*5 square convolution kernel\n",
    "        self.conv1 = nn.Conv2d(1,6,5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120) # 5*5 image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2,2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        # flatten all dimensions except the batch dimension\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0ed3a97-1d2c-4072-969c-6e6adeec14ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa20c1f9-f372-4355-81ee-233be4b1a1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750b7252-5032-42a1-9a0b-99702970b8ec",
   "metadata": {},
   "source": [
    "> 您只需要定义forward函数， 就可以使用autograd为您自动定义的backward函数（计算梯度）。您可以在forward函数中使用任何张量操作。\n",
    "\n",
    "> 模型的可以学习参数由 net.parameters() 返回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d13725f5-5634-48ed-96db-24cec49e8d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x000002C7C064AE40>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dee62fd1-d324-4ffb-8825-fdf9f2163566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c71d2b9-59da-4292-9750-775bb993b6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(net.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "961ca21c-8fe0-40cd-b344-db8cf08a6e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76ee4321-1a58-4423-978f-98c3f80b7c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1, 5, 5])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3a2169f-da08-43ba-8f03-9413c5fb2a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "298335a6-ec7b-4a90-85df-e22eee354666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 6, 5, 5])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[2].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e68a8deb-f710-48c3-9035-d87fc5c3dd6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[3].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c95b135c-7a95-4983-b685-e6811f9d402b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 400])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[4].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "892d212b-e4e2-4750-8e92-6c474d52066c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[5].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc2d613b-e572-4464-a555-11813f58790b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([84, 120])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[6].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "352e28ef-ccc1-4329-aaac-d56496e24052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([84])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[7].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3c98e33-e6a6-4a37-8180-6b29ecf81dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 84])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[8].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e00450e7-ab08-48ed-89d4-b87eb21a0063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[9].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2889b4c8-2be0-4cf1-af9c-8a2425cb88eb",
   "metadata": {},
   "source": [
    "> 让我们尝试一个 32 * 32 的随机输入。 注意该网络的预期输入大小（LeNet）为32*32 。要在MNIST数据集上使用此网络，请将图像从数据集中调整为32*32。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a63f519-e693-41df-84dd-55e9c7f19837",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1, 1, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c623454f-6aff-4e7b-baad-b1202c618d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.6879,  1.3057,  1.3715,  ..., -1.4337, -2.0822,  0.2898],\n",
       "          [ 0.1196, -0.6910,  0.4534,  ..., -0.5788, -0.1214,  0.3163],\n",
       "          [-0.3782,  1.4453,  0.3271,  ..., -1.2923, -0.4578,  1.2522],\n",
       "          ...,\n",
       "          [-1.3988, -0.5945,  1.2240,  ..., -1.2059, -1.1987, -0.2059],\n",
       "          [-0.3658,  0.0668,  1.0944,  ...,  0.4230,  0.7303, -0.4681],\n",
       "          [ 1.5490, -0.5790, -0.2589,  ...,  1.5986,  0.0743, -0.1137]]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2985dc98-bf8a-4594-97f2-8730a51c0c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "out = net(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cff69aad-b1db-4de1-a023-a12f37684f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0751, -0.0740, -0.0316,  0.0862, -0.0508, -0.0083, -0.0213, -0.0867,\n",
       "          0.0594, -0.0045]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54c1e01-f6dd-4a0d-b8d5-c094d3fdb2dd",
   "metadata": {},
   "source": [
    "> 使用随机梯度将所有参数和反向传播的缓冲区归零："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4eae4f8d-03f2-43f4-9f79-0da3b1632ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a2ee46dd-57a4-4245-96a6-9fc33cc0f264",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20230f6e-43df-489e-94ff-e37869e20c96",
   "metadata": {},
   "source": [
    "> torch.nn 仅支持小批量。整个torch.nn 包仅支持作为微型样本而不是单个样本的输入。\n",
    "\n",
    "> 例如： nn.Conv2d 将采用 nSamples * nChannels * Height * Width 的4D张量。\n",
    "\n",
    "> 如果您只有一个样本， 只需要使用 input.unsqueeze(0) 添加一个假批量尺寸。\n",
    "\n",
    "> 在继续之前，我们回顾一下到目前为止看到的所有类。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060bdb23-3bc8-4d92-a483-4c230fc3f0db",
   "metadata": {},
   "source": [
    "* torch.Tensor 一个多维数组， 支持如 backward()的自动微分操作。同样，保持相对于张量的梯度。\n",
    "* nn.Module 神经网络模块， 封装参数的便捷方法， 并带有将其移动到GPU、导出、加载等的帮助器。\n",
    "* nn.Parameter 一种张量，即将其分配为 Module 的属性时， 自动注册为参数。\n",
    "* autograd.Fuction 实现自动微分操作的正向和反向定义。每个Tensor操作都会创建至少一个Function节点， 该节点连接到创建Tensor的函数，并且编码器历史记录\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47faab45-7756-47da-aafe-f75f46f3c71b",
   "metadata": {},
   "source": [
    "### 3. 损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9dd5f7-ca91-44f2-bf45-2f2522dee15b",
   "metadata": {},
   "source": [
    "> 损失函数采用一对（输出， 目标）输入， 并计算一个值， 该值估计输出与目标之间的距离。\n",
    "\n",
    "> nn 包含多种不同的损失函数。一个简单的损失函数是：nn.MSELoss, 它计算输入和目标之间的均方误差。\n",
    "\n",
    "> *例如：*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "18443dd4-a948-4ac0-b293-d9e471454d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([1, 10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "# a dummy target, for example\n",
    "target = torch.randn(10)\n",
    "# make it the same shape as output\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d7ae909-ddfb-48af-8ca9-a5b2a6773105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5263, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04f2079b-9f93-4067-8e7e-5a590efbc353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 现在， 如果使用 .grad_fn 属性向后跟随 loss， 您将看到一个计算图， 如下所示："
   ]
  },
  {
   "cell_type": "raw",
   "id": "2693e30a-c230-4cd2-8bb3-3c8b430a39cb",
   "metadata": {},
   "source": [
    "input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n",
    "      -> view -> linear -> relu -> linear -> relu -> linear\n",
    "      -> MSELoss\n",
    "      -> loss"
   ]
  },
  {
   "cell_type": "raw",
   "id": "66d1aee2-046c-4382-ac58-0969b78b210a",
   "metadata": {},
   "source": [
    "因此，当我们调用loss.backward()时，整个图将被微分。 损失，并且图中具有requires_grad=True的所有张量将随梯度累积其.grad张量。\n",
    "\n",
    "为了说明，让我们向后走几步："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4b56383-edb7-41d2-855f-963c3418f296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MseLossBackward at 0x2c7c0db5070>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "514fe67d-e2e3-4556-885f-14a21626313d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<AddmmBackward at 0x2c7c1366460>, 0), (None, 0))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.grad_fn.next_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75210f71-d2cc-4424-a768-2338545ad112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AddmmBackward at 0x2c7c1366460>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.grad_fn.next_functions[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a6a924c3-4f8f-4054-9240-030114c80805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<AccumulateGrad at 0x2c7c0db5490>, 0),\n",
       " (<ReluBackward0 at 0x2c7c0fab8e0>, 0),\n",
       " (<TBackward at 0x2c7c0fab400>, 0))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.grad_fn.next_functions[0][0].next_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eecf3f96-5ddb-4501-82f3-08c539b81620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AccumulateGrad at 0x2c7c0db5490>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.grad_fn.next_functions[0][0].next_functions[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c965cd4-7cbd-406c-9cf4-dc14d536b4e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081de386-dc9f-4794-b836-45e7e0cfb18e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49085b28-74b3-4aca-a357-0ceba0f85b86",
   "metadata": {},
   "source": [
    "### 4. 反向传播"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b23cfe11-e2a8-4a0c-8bfb-c01eb56afa15",
   "metadata": {},
   "source": [
    "要反向传播误差，我们要做的只是对loss.backward()。 不过，您需要清除现有的梯度，否则梯度将累积到现有的梯度中。\n",
    "\n",
    "现在，我们将其称为loss.backward()，然后看一下向后前后conv1的偏差梯度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "863a7d72-edaf-4c88-a3c1-57419532946d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zeroes the gradient buffers os all parameters\n",
    "net.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ca133132-16ed-42dc-8745-4a4e0a254c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3c1a9df8-e2a5-49f7-9545-3a20e2fb860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3ef79927-e1aa-4250-ac41-29577dcd2653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad after backward\n",
      "tensor([-0.0010,  0.0077, -0.0088,  0.0165, -0.0166, -0.0211])\n"
     ]
    }
   ],
   "source": [
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ff7f3263-3cf2-4557-b355-0db113e920a3",
   "metadata": {},
   "source": [
    "现在，我们已经看到了如何使用损失函数。"
   ]
  },
  {
   "cell_type": "raw",
   "id": "00043ac4-d234-468b-a447-34b09fd786b8",
   "metadata": {},
   "source": [
    "稍后阅读：\n",
    "\n",
    "神经网络包包含各种模块和损失函数，这些模块和损失函数构成了深度神经网络的构建块。 带有文档的完整列表位于此处。\n",
    "\n",
    "唯一需要学习的是：\n",
    "\n",
    "更新网络的权重"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd82e1e-eaf5-4d7d-b4b1-7e0b9faeae8e",
   "metadata": {},
   "source": [
    "### 5. 更新权重"
   ]
  },
  {
   "cell_type": "raw",
   "id": "620cf850-3fb3-48f9-ae9e-3b19e8992dbc",
   "metadata": {},
   "source": [
    "实践中使用的最简单的更新规则是随机梯度下降（SGD）："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e06ebf5-c372-4ed3-8fb4-57a0c0d7978e",
   "metadata": {},
   "source": [
    "> weight = weight - learning_rate * gradient"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a6de7789-5d55-4456-9795-148eb2c5b16d",
   "metadata": {},
   "source": [
    "简单的python 代码实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d9cf9575-bb9e-4260-a1eb-c16707b8a0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6bee324f-cd8d-4ade-8446-ea7302172f27",
   "metadata": {},
   "source": [
    "但是，在使用神经网络时，您希望使用各种不同的更新规则，例如 SGD，Nesterov-SGD，Adam，RMSProp 等。为实现此目的，我们构建了一个小包装：torch.optim，可实现所有这些方法。 使用它非常简单："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b07ca8e6-c695-4097-9be5-aa99c4906c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5d354988-d35d-4c7c-b7fd-7830f6685826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "01dde6a0-3ea9-482f-b89e-c44a46de74a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in your training loop:\n",
    "# zero the gradient buffers\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7881c22d-f8fa-4550-80cc-2a2d3e9b6781",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = net(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9b1ff1f5-4154-4d4e-8b29-921378e4a394",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([1, 10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "loss = criterion(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e387c920-01cd-47bc-afa7-378b2560421a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "# does the update\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d1b8d3-a892-4e03-bfb4-5fb2510765bc",
   "metadata": {},
   "source": [
    "> 注意\n",
    "\n",
    "> 观察如何使用optimizer.zero_grad()将梯度缓冲区手动设置为零。 这是因为如反向传播部分中所述累积了梯度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757d75b3-0ee9-4634-9f3b-f168cd0e13ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e25a339-1b8c-41c2-aed4-db75c8686e03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e232979-1233-47ec-9d3b-8735df10747f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
