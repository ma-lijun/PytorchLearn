{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba85c5e3-ba48-4a77-ba93-d9d9823b5c3e",
   "metadata": {},
   "source": [
    "1.3 Pytorch Neural Networks(神经网络)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dcb43a-1bb2-4371-ad75-7c79de1a97d6",
   "metadata": {},
   "source": [
    "### 1. 使用torch.nn包来构建神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62af99b-1ddc-42d6-b135-1702e33d5e4e",
   "metadata": {},
   "source": [
    "> 由上一讲了解了autograd, nn包依赖 autograd 包来定义模型并求导。一个nn.Module包含各个层和一个forward(input)方法，该方法返回output。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b075f989-2eb1-44e5-b2c5-8d38da8b5857",
   "metadata": {},
   "source": [
    "![Alexnet网络示例](./img/alexnet20220517154203.png \"网络模型\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f5b39b-97c1-4641-ab2f-d76a1e0802f9",
   "metadata": {},
   "source": [
    "> 这是一个简单的前馈神经网络， 它接受一个输入， 然后一层接着一层地传递， 最后输出计算结果。\n",
    "\n",
    "> 神经网络的典型训练过程如下：\n",
    "\n",
    "    1. 定义包含一些可学习参数（或者叫权重）的神经网络模型；\n",
    "    2. 在数据集上迭代；\n",
    "    3. 通过神经网络处理输入；\n",
    "    4. 计算损失（输出结果和正确值的差值大小）；\n",
    "    5. 将梯度反向传播回网格的参数；\n",
    "    6. 更新网格的参数， 主要使用如下简单的更新原则： weight = weight - learning_rate*gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe43331-4e42-4b19-9426-cb1082ffc60b",
   "metadata": {},
   "source": [
    "### 2. 定义网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ff49e69-bb45-4e0d-b930-1009d47857a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718dba39-b50c-4137-9d53-19cfa453b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5*5 square convolution kernel\n",
    "        self.conv1 = nn.Conv2d(1,6,5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120) # 5*5 image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2,2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        # flatten all dimensions except the batch dimension\n",
    "        x = torch.flatten(x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13725f5-5634-48ed-96db-24cec49e8d32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bdec8c-e96b-46b1-90dc-f37d4ced9d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a63f519-e693-41df-84dd-55e9c7f19837",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
